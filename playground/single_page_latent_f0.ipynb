{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import *\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "from numpy.fft import rfft\n",
    "from numpy import pi\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import cmath\n",
    "import scipy\n",
    "from scipy.signal import stft\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from cache_no_hash import cache\n",
    "from blindDescend import blindDescend\n",
    "from yin import yin\n",
    "from harmonicSynth import HarmonicSynth, Harmonic\n",
    "\n",
    "TWO_PI = np.pi * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.chdir('playground')\n",
    "except FileNotFoundError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')\n",
    "from shared import *\n",
    "from lobe import getLobe\n",
    "from manual_fc import ManualFC\n",
    "from hyper_params import HyperParams\n",
    "from nitf import NITF\n",
    "from dataset_definitions import DatasetDefinition\n",
    "os.chdir('playground')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sino(freq, length):\n",
    "    return np.sin(np.arange(length) * freq * TWO_PI / SR)\n",
    "\n",
    "def playHard(data):\n",
    "    return Audio(data, rate = SR)\n",
    "def play(data, soft = .1):\n",
    "    t = np.concatenate([data, [1]])\n",
    "    length = round(soft * SR)\n",
    "    t[:length ] = np.multiply(t[:length ], np.linspace(0, 1, length))\n",
    "    t[-length:] = np.multiply(t[-length:], np.linspace(1, 0, length))\n",
    "    return playHard(t)\n",
    "\n",
    "def findPeaks(energy):\n",
    "    slope = np.sign(energy[1:] - energy[:-1])\n",
    "    extrema = slope[1:] - slope[:-1]\n",
    "    return np.argpartition(\n",
    "        (extrema == -2) * energy[1:-1], - N_HARMONICS,\n",
    "    )[- N_HARMONICS:] + 1\n",
    "\n",
    "def sft(signal, freq_bin):\n",
    "    # Slow Fourier Transform\n",
    "    return np.abs(np.sum(signal * np.exp(IMAGINARY_LADDER * freq_bin))) / PAGE_LEN\n",
    "\n",
    "def refineGuess(guess, signal):\n",
    "    def loss(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        return - sft(signal, x)\n",
    "    freq_bin, loss = blindDescend(loss, .01, .4, guess)\n",
    "    return freq_bin * SR / PAGE_LEN, - loss\n",
    "\n",
    "def widePlot(h = 3, w = 12):\n",
    "    plt.gcf().set_size_inches(w, h)\n",
    "    \n",
    "def spectrum(signal, do_wide = True, trim = 130):\n",
    "    energy = np.abs(rfft(signal * HANN)) / (PAGE_LEN / 2)\n",
    "    X = np.linspace(0, SR / 2, len(energy))\n",
    "    plt.plot(\n",
    "        X     [:trim], \n",
    "        energy[:trim], \n",
    "    )\n",
    "    plt.xlabel('freq (Hz)')\n",
    "    if do_wide:\n",
    "        widePlot()\n",
    "    return energy\n",
    "\n",
    "def spectrogram(signal, **kw):\n",
    "    f, t, Zxx = stft(signal, fs=SR, **kw)\n",
    "    plt.pcolormesh(t, f, np.abs(Zxx))\n",
    "\n",
    "def concatSynth(synth, harmonics, n):\n",
    "    buffer = []\n",
    "    for i in range(n):\n",
    "        synth.eat(harmonics)\n",
    "        buffer.append(synth.mix())\n",
    "    return np.concatenate(buffer)\n",
    "\n",
    "def pitch2freq(pitch):\n",
    "    return np.exp((pitch + 36.37631656229591) * 0.0577622650466621)\n",
    "\n",
    "def freq2pitch(f):\n",
    "    return np.log(f) * 17.312340490667562 - 36.37631656229591\n",
    "\n",
    "def pagesOf(signal):\n",
    "    for i in range(0, signal.size - PAGE_LEN + 1, PAGE_LEN):\n",
    "        yield signal[i : i + PAGE_LEN]\n",
    "\n",
    "def plotUnstretchedPartials(f0, n_partials = 14, color = 'r', alpha = .3):\n",
    "    for i in range(1, n_partials + 1):\n",
    "        freq = f0 * i\n",
    "        plt.axvline(x = freq, color = color, alpha = alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_points = [\n",
    "    (700, .2), \n",
    "    (950, .05), \n",
    "    (2400, .05), \n",
    "    (2800, 0), \n",
    "    (3000, 0), \n",
    "]\n",
    "timbre = ManualFC(\n",
    "    torch.tensor([x[0] for x in timbre_points]), \n",
    "    torch.tensor([x[1] for x in timbre_points]), \n",
    ")\n",
    "X = torch.linspace(0, NYQUIST, 1000)\n",
    "plt.plot(X, timbre(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f0 = 300\n",
    "lobe = getLobe()\n",
    "y = []\n",
    "for i in range(N_HARMONICS):\n",
    "    freq = f0 * (i + 1)\n",
    "    mag = timbre(torch.tensor(freq)).numpy()\n",
    "    y.append(sino(freq, SR) * mag)\n",
    "y_long = np.stack(y).sum(axis=0)\n",
    "y = y_long[:PAGE_LEN]\n",
    "energy = np.abs(rfft(y * HANN)) / (PAGE_LEN / 2)\n",
    "energy = torch.tensor(energy).float()\n",
    "plt.plot(energy)\n",
    "play(y_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.linspace(0, NYQUIST, SPECTRUM_SIZE)\n",
    "freq_bin: float = freqs[1]\n",
    "one_over_freq_bin = torch.tensor(1 / freq_bin).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqCube = torch.arange(0, SPECTRUM_SIZE).float()\n",
    "freqCube = freqCube.unsqueeze(0).repeat(N_HARMONICS, 1)\n",
    "freqCube.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LADDER = torch.arange(0, N_HARMONICS).float().contiguous() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(f0):\n",
    "    freq = f0 * LADDER\n",
    "    mag = timbre(freq)\n",
    "    x = freqCube - (freq * one_over_freq_bin).unsqueeze(1)\n",
    "    x = lobe(x)\n",
    "    x = x * mag.unsqueeze(1)\n",
    "    return x.sum(dim=0)\n",
    "\n",
    "plt.plot(forward(f0), linewidth=4)\n",
    "plt.plot(energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_f0 = torch.tensor(160.0, requires_grad=True)\n",
    "optim = torch.optim.Adam([latent_f0], lr=1)\n",
    "for epoch in range(10):\n",
    "    spec_hat = forward(latent_f0)\n",
    "    loss = F.mse_loss(spec_hat, energy)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    print(epoch, loss.item(), latent_f0.item())\n",
    "    # sleep(.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(forward(latent_f0).detach(), linewidth=4)\n",
    "plt.plot(energy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damn, we need multi-hot octave!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMES = (2,3,5,7,11,13)\n",
    "DREDGE_RADIUS = 2\n",
    "DREDGE_MULT = torch.ones((DREDGE_RADIUS * 2 + 1, )).float()\n",
    "for i in range(DREDGE_RADIUS):\n",
    "    DREDGE_MULT[DREDGE_RADIUS - i - 1] = 1 / PRIMES[i]\n",
    "    DREDGE_MULT[DREDGE_RADIUS + i + 1] = PRIMES[i]\n",
    "DREDGE_MULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dredge:\n",
    "    def __init__(self, guess=200) -> None:\n",
    "        self.freq = torch.tensor(\n",
    "            float(freqNorm(guess)), \n",
    "            dtype=torch.float32, requires_grad=True, \n",
    "        )\n",
    "        self.vector = torch.zeros(\n",
    "            (DREDGE_RADIUS * 2 + 1, ), \n",
    "            dtype=torch.float32, \n",
    "        )\n",
    "        self.vector[DREDGE_RADIUS] = 1\n",
    "        self.vector.requires_grad = True\n",
    "    \n",
    "    def eval(self):\n",
    "        return (DREDGE_MULT * freqDenorm(self.freq), self.vector)\n",
    "\n",
    "    def simplify(self):\n",
    "        old_vector = self.vector.detach()\n",
    "        i = old_vector.argmax()\n",
    "        if old_vector[i] / old_vector[DREDGE_RADIUS] < 2:\n",
    "            return\n",
    "        vector = torch.zeros(\n",
    "            (DREDGE_RADIUS * 2 + 1, ), \n",
    "            dtype=torch.float32, \n",
    "        )\n",
    "        vector[DREDGE_RADIUS] = old_vector[i]\n",
    "        vector[DREDGE_RADIUS * 2 - i] = old_vector[DREDGE_RADIUS]\n",
    "        vector.requires_grad = True\n",
    "        self.vector = vector\n",
    "        self.freq = freqNorm(freqDenorm(self.freq.detach()) * DREDGE_MULT[i])\n",
    "        self.freq.requires_grad = True\n",
    "    \n",
    "    def parameters(self):\n",
    "        return (self.freq, self.vector)\n",
    "\n",
    "d = Dredge()\n",
    "print(d.eval())\n",
    "optim = torch.optim.Adam(d.parameters(), lr=1e-2)\n",
    "for epoch in range(100):\n",
    "    loss = (d.vector[4] - 0.8) ** 2 + (d.vector[3] - 0.1) ** 2\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "print(d.eval())\n",
    "d.simplify()\n",
    "print(d.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDredge(dredge, ground_truth_energy, max_epoch=100, lr=1e-2):\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch % 16 == 0):\n",
    "            optim = torch.optim.Adam(dredge.parameters(), lr=lr)\n",
    "            dredge.simplify()\n",
    "        f0s, confidences = dredge.eval()\n",
    "        spec_hat = []\n",
    "        for i in range(f0s.shape[0]):\n",
    "            spec_hat.append(forward(f0s[i]) * confidences[i])\n",
    "        spec_hat = torch.stack(spec_hat, dim=0).sum(dim=0)\n",
    "        loss = F.mse_loss(spec_hat, ground_truth_energy)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        yield epoch, loss, spec_hat\n",
    "\n",
    "dredge = Dredge(450)\n",
    "for epoch, loss, _ in trainDredge(dredge, energy):\n",
    "    # print(epoch, loss.item())\n",
    "    print(freqDenorm(dredge.freq).item())\n",
    "    print(dredge.vector)\n",
    "    # sleep(.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_name = 'dan'\n",
    "audio_name = 'voice_scale'\n",
    "\n",
    "y, sr = librosa.load(f'../dataset/{audio_name}.wav', sr=SR)\n",
    "assert sr == SR\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if audio_name == 'dan':\n",
    "    seg = y[7400:8500]\n",
    "else:\n",
    "    # seg_start = round(.25 * SR)\n",
    "    seg_start = round(.97 * SR)\n",
    "    seg = y[seg_start:seg_start + PAGE_LEN * 4]\n",
    "spectrogram(seg)\n",
    "playHard(seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energies = []\n",
    "for page in pagesOf(seg):\n",
    "    f0 = yin(page, SR, PAGE_LEN)\n",
    "    print(f0)\n",
    "    energy = spectrum(page, trim=60)\n",
    "    energies.append(torch.tensor(energy).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timbre_points = [\n",
    "    (400, .015), \n",
    "    (450, .03), \n",
    "    (500, .03), \n",
    "    (550, 0.005), \n",
    "    (750, 0.002), \n",
    "    (800, .01), \n",
    "    (850, .01), \n",
    "    (950, 0), \n",
    "    (960, 0), \n",
    "]\n",
    "timbre = ManualFC(\n",
    "    torch.tensor([x[0] for x in timbre_points]), \n",
    "    torch.tensor([x[1] for x in timbre_points]) * 8 / 3, \n",
    ")\n",
    "X = torch.linspace(0, 2500, 1000)\n",
    "plt.plot(X, timbre(X))\n",
    "widePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(f0):\n",
    "    freq = f0 * LADDER\n",
    "    mag = timbre(freq)\n",
    "    x = freqCube - (freq * one_over_freq_bin).unsqueeze(1)\n",
    "    x = lobe(x)\n",
    "    x = x * mag.unsqueeze(1)\n",
    "    return x.sum(dim=0)\n",
    "\n",
    "plt.plot(forward(f0)[:60], linewidth=4)\n",
    "plt.plot(energy[:60])\n",
    "widePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [*pagesOf(seg)]\n",
    "dredges = [Dredge(100) for _ in pages]\n",
    "spec_hats = [None] * len(pages)\n",
    "hist_freq = [[] for _ in pages]\n",
    "hist_conf = [[] for _ in pages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainVoice(max_epoch=100):\n",
    "    trainers = []\n",
    "    for d, e in zip(dredges, energies):\n",
    "        trainers.append(trainDredge(d, e, max_epoch, lr=2e-2))\n",
    "    for epoch in range(max_epoch):\n",
    "        print(epoch)\n",
    "        for i, trainer in enumerate(trainers):\n",
    "            _, loss, spec_hat = next(trainer)\n",
    "            spec_hats[i] = spec_hat\n",
    "            print(round(freqDenorm(dredges[i].freq.item())), end=', ')\n",
    "            # print(d.vector)\n",
    "            hist_freq[i].append(dredges[i].freq.detach().item())\n",
    "            hist_conf[i].append(dredges[i].vector.detach().clone())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dredges = [Dredge(100) for _ in pages]\n",
    "spec_hats = [None] * len(pages)\n",
    "hist_freq = [[] for _ in pages]\n",
    "hist_conf = [[] for _ in pages]\n",
    "# trainVoice(200)\n",
    "trainVoice(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "plt.plot([freqDenorm(x) for x in hist_freq[i]], 'o')\n",
    "plt.plot([x[3] * 100 for x in hist_conf[i]])\n",
    "widePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(spec_hats[i].detach())\n",
    "plt.plot(energies[i])\n",
    "dredges[i].eval()\n",
    "# dredges[i].vector.grad"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for 3:2, it woudln't first / 3 then * 2. local min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RATIOS = [3/2, 2, 3]\n",
    "DREDGE_RADIUS = len(RATIOS)\n",
    "DREDGE_MULT = torch.ones((DREDGE_RADIUS * 2 + 1, )).float()\n",
    "for i in range(DREDGE_RADIUS):\n",
    "    DREDGE_MULT[DREDGE_RADIUS - i - 1] = 1 / RATIOS[i]\n",
    "    DREDGE_MULT[DREDGE_RADIUS + i + 1] = RATIOS[i]\n",
    "DREDGE_MULT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it works. now add regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reguLoss(vector: torch.Tensor):\n",
    "    loss = - vector.clip(max=0).sum()\n",
    "    acc = torch.tensor(0).float()\n",
    "    pos_v = vector.clip(min=0)\n",
    "    de_pos_v = pos_v.detach()\n",
    "    for i in range(vector.shape[0]):\n",
    "        loss = loss + pos_v[i] * acc.clone()\n",
    "        acc += de_pos_v[i]\n",
    "    return loss\n",
    "\n",
    "def trainDredge(dredge: Dredge, ground_truth_energy, max_epoch=100, lr=1e-2):\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch % 16 == 0):\n",
    "            optim = torch.optim.Adam(dredge.parameters(), lr=lr)\n",
    "            dredge.simplify()\n",
    "        f0s, confidences = dredge.eval()\n",
    "        spec_hat = []\n",
    "        for i in range(f0s.shape[0]):\n",
    "            spec_hat.append(forward(f0s[i]) * confidences[i])\n",
    "        spec_hat = torch.stack(spec_hat, dim=0).sum(dim=0)\n",
    "        loss = F.mse_loss(spec_hat, ground_truth_energy)\n",
    "        loss = loss + reguLoss(dredge.vector) * 1e-5\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        yield epoch, loss, spec_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dredges = [Dredge(100) for _ in pages]\n",
    "spec_hats = [None] * len(pages)\n",
    "hist_freq = [[] for _ in pages]\n",
    "hist_conf = [[] for _ in pages]\n",
    "# trainVoice(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "plt.plot([freqDenorm(x) for x in hist_freq[i]], 'o')\n",
    "plt.plot([x[3] * 100 for x in hist_conf[i]])\n",
    "widePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dredges:\n",
    "    print(d.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trajs(max_epoch=100, n_guesses=100):\n",
    "    e = energies[0]\n",
    "    trainers = []\n",
    "    dredges: List[Dredge] = []\n",
    "    for guess_f0 in np.linspace(\n",
    "        pitch2freq(36), \n",
    "        pitch2freq(72), \n",
    "        n_guesses, \n",
    "    ):\n",
    "        d = Dredge(guess_f0)\n",
    "        dredges.append(d)\n",
    "        trainers.append(trainDredge(d, e, max_epoch, lr=2e-2))\n",
    "    for epoch in tqdm([*range(max_epoch)]):\n",
    "        # print(epoch)\n",
    "        for i, trainer in enumerate(trainers):\n",
    "            _, loss, spec_hat = next(trainer)\n",
    "            spec_hats[i] = spec_hat\n",
    "            # print(d.vector)\n",
    "            hist_freq[i].append(dredges[i].freq.detach().item())\n",
    "            hist_conf[i].append(dredges[i].vector.detach().clone())\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_guesses = 100\n",
    "n_guesses = 20\n",
    "spec_hats = [None] * n_guesses\n",
    "hist_freq = [[] for _ in range(n_guesses)]\n",
    "hist_conf = [[] for _ in range(n_guesses)]\n",
    "# trajs(300, n_guesses)\n",
    "trajs(3, n_guesses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fs in hist_freq:\n",
    "    plt.plot([freqDenorm(x) for x in fs], c='k', linewidth=.5)\n",
    "    plt.plot([0, len(fs)], [freqDenorm(fs[0]), freqDenorm(fs[-1])], c='r', linewidth=.5)\n",
    "plt.axhline(141, c='g', label='Truth')\n",
    "plt.ylim(0, 700)\n",
    "plt.legend()\n",
    "plt.ylabel('F0 (Hz)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joint optim the timbre too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = HyperParams()\n",
    "template.lr = None\n",
    "template.weight_decay = 1e-9\n",
    "template.optim_name = 'adam'\n",
    "template.nif_width = 128\n",
    "template.nif_depth = 6\n",
    "template.n_vowel_dims = 2\n",
    "template.nif_sees_f0 = False\n",
    "template.nif_sees_amp = False\n",
    "template.nif_sees_vowel = False\n",
    "template.nif_abs_out = True\n",
    "template.nif_abs_confidence = False\n",
    "template.ground_truth_f0 = False\n",
    "template.batch_size = 256\n",
    "template.max_epoch = 600\n",
    "hParams = template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dDef = DatasetDefinition()\n",
    "dDef.is_f0_latent = False\n",
    "hParams.experiment_globals = {\n",
    "    'datasetDef': dDef, \n",
    "    'dataset': None, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viewEnv(nitf):\n",
    "    with torch.no_grad():\n",
    "        X = torch.linspace(\n",
    "            pitch2freq(36), \n",
    "            NYQUIST, \n",
    "            1000, \n",
    "        )\n",
    "        X = X.unsqueeze(1)\n",
    "        Y = nitf.forward(freqNorm(X))\n",
    "        plt.plot(X, Y, label='nitf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nitf = NITF(hParams, False)\n",
    "viewEnv(nitf)\n",
    "widePlot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timbre(freq):\n",
    "    return nitf(freqNorm(freq.unsqueeze(1)))[:, 0]\n",
    "def trainDredge(dredge: Dredge, ground_truth_energy, max_epoch=100, lr=1e-2):\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch % 16 == 0):\n",
    "            optim = torch.optim.Adam([\n",
    "                *dredge.parameters(), \n",
    "                *nitf.parameters(), \n",
    "            ], lr=lr)\n",
    "            dredge.simplify()\n",
    "        f0s, confidences = dredge.eval()\n",
    "        confidences = confidences.abs()\n",
    "        spec_hat = []\n",
    "        for i in range(f0s.shape[0]):\n",
    "            spec_hat.append(forward(f0s[i]) * confidences[i])\n",
    "        spec_hat = torch.stack(spec_hat, dim=0).sum(dim=0)\n",
    "        loss = F.mse_loss(spec_hat, ground_truth_energy)\n",
    "        loss = loss + reguLoss(dredge.vector) * 1e-6\n",
    "        yield epoch, loss, spec_hat\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        with torch.no_grad():\n",
    "            dredge.vector /= dredge.vector.norm()\n",
    "\n",
    "def trainVoice(max_epoch=100):\n",
    "    trainers = []\n",
    "    for d, e in zip(dredges, energies):\n",
    "        trainers.append(trainDredge(d, e, max_epoch, lr=1e-2))\n",
    "    for epoch in range(max_epoch):\n",
    "        # print(epoch)\n",
    "        for i, trainer in enumerate(trainers):\n",
    "            _, loss, spec_hat = next(trainer)\n",
    "            with torch.no_grad():\n",
    "                spec_hats[i] = spec_hat\n",
    "                # print(round(freqDenorm(dredges[i].freq.item())), end=', ')\n",
    "                # print(d.vector)\n",
    "                hist_freq[i].append(dredges[i].freq.detach().item())\n",
    "                hist_conf[i].append(dredges[i].vector.detach().clone())\n",
    "                plt.cla()\n",
    "                plt.plot(freqs, energies[i], label='truth')\n",
    "                plt.plot(freqs, spec_hat, label='recon')\n",
    "                viewEnv(nitf)\n",
    "                F, C = dredges[i].eval()\n",
    "                kw = dict(label='dredge')\n",
    "                plt.vlines(\n",
    "                    F, ymin=0, ymax=C.abs() * .02, colors='k', **kw, \n",
    "                )\n",
    "                # for f, c in zip(F, C):\n",
    "                #     plt.vlines(\n",
    "                #         f, ymin=0, ymax=c.abs().item(), colors='k', **kw, \n",
    "                #     )\n",
    "                #     kw.clear()\n",
    "                plt.legend()\n",
    "        yield\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pages[:1]\n",
    "dredges = [Dredge(300) for _ in pages]\n",
    "spec_hats = [None] * len(pages)\n",
    "hist_freq = [[] for _ in pages]\n",
    "hist_conf = [[] for _ in pages]\n",
    "nitf = NITF(hParams, False)\n",
    "tv = trainVoice(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "for _ in tqdm([*range(50)]):\n",
    "    next(tv)\n",
    "    epoch += 1\n",
    "widePlot()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dredges[0].eval()\n",
    "# DREDGE_MULT\n",
    "print(dredges[0].vector)\n",
    "dredges[0].vector.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "plt.plot([freqDenorm(x) for x in hist_freq[i]], 'o')\n",
    "plt.plot([x[0] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[1] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[2] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[3] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[4] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[5] * 100 for x in hist_conf[i]])\n",
    "plt.plot([x[6] * 100 for x in hist_conf[i]])\n",
    "widePlot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDredge(dredge: Dredge, ground_truth_energy, max_epoch=100, lr=1e-2):\n",
    "    optimNitf = torch.optim.Adam([\n",
    "        *nitf.parameters(), \n",
    "    ], lr=1e-3)\n",
    "    for epoch in range(max_epoch):\n",
    "        if (epoch % 16 == 0):\n",
    "            optimFreq = torch.optim.Adam([\n",
    "                dredge.freq, \n",
    "            ], lr=1e-3)\n",
    "            optimVector = torch.optim.Adam([\n",
    "                dredge.vector, \n",
    "            ], lr=1e-2)\n",
    "            dredge.simplify()\n",
    "        f0s, confidences = dredge.eval()\n",
    "        confidences = confidences.abs()\n",
    "        spec_hat = []\n",
    "        for i in range(f0s.shape[0]):\n",
    "            spec_hat.append(forward(f0s[i]) * confidences[i])\n",
    "        spec_hat = torch.stack(spec_hat, dim=0).sum(dim=0)\n",
    "        loss = F.mse_loss(spec_hat, ground_truth_energy)\n",
    "        loss = loss + reguLoss(dredge.vector) * 1e-6\n",
    "        yield epoch, loss, spec_hat\n",
    "        optimNitf.zero_grad()\n",
    "        optimFreq.zero_grad()\n",
    "        optimVector.zero_grad()\n",
    "        loss.backward()\n",
    "        optimNitf.step()\n",
    "        optimFreq.step()\n",
    "        optimVector.step()\n",
    "        with torch.no_grad():\n",
    "            dredge.vector /= dredge.vector.norm()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pages[:1]\n",
    "dredges = [Dredge(300) for _ in pages]\n",
    "spec_hats = [None] * len(pages)\n",
    "hist_freq = [[] for _ in pages]\n",
    "hist_conf = [[] for _ in pages]\n",
    "nitf = NITF(hParams, False)\n",
    "N_EPOCHS = 1000\n",
    "tv = trainVoice(N_EPOCHS)\n",
    "epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in tqdm([*range(\n",
    "    N_EPOCHS, \n",
    "    # 10, \n",
    ")]):\n",
    "    next(tv)\n",
    "    plt.ylim(0, .04)\n",
    "    plt.xlabel('Freq (Hz)')\n",
    "    plt.title(f'epoch {epoch}')\n",
    "    widePlot(6, 12)\n",
    "    plt.savefig(f'./vid_out/a_{epoch}.png')\n",
    "    epoch += 1\n",
    "widePlot()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
